import os
import json
from datetime import datetime
from dotenv import load_dotenv
import google.generativeai as genai
from docx import Document
import PyPDF2
import pandas as pd
from pathlib import Path
import re
import unidecode # Necesario para la normalizaciÃ³n de nombres

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Directorios
TEMPLATES_DIR = "templates_docs"
DATA_DIR = "data_docs"
OUTPUT_DIR = "output_docs"
MAPPINGS_DIR = "mappings_docs"

for dir_path in [TEMPLATES_DIR, DATA_DIR, OUTPUT_DIR, MAPPINGS_DIR]:
    os.makedirs(dir_path, exist_ok=True)

class DocumentFiller:
    def __init__(self):
        self.model = genai.GenerativeModel("gemini-1.5-flash")
        self.supported_template_formats = ['.docx', '.txt', '.pdf']
        self.supported_data_formats = ['.json', '.csv', '.xlsx', '.txt']
        
        # ğŸ†• Cargar mapeos
        self.mappings_cache = {}
        self.default_mapping = self.load_mapping_file('default.json')
        
        # Base de datos maestra del usuario
        self.user_database_file = os.path.join(DATA_DIR, "_master_user_data.json")
        self.user_database = self.load_master_database()
        self.output_dir = OUTPUT_DIR

    # ============= ğŸ†• GESTIÃ“N DE MAPEOS =============
    
    def load_mapping_file(self, filename: str) -> dict:
        """Carga un archivo de mapeo"""
        try:
            filepath = os.path.join(MAPPINGS_DIR, filename)
            
            if not os.path.exists(filepath):
                if filename == 'default.json':
                    return self.create_default_mapping()
                return None
            
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Error cargando mapeo {filename}: {e}")
            return None
    
    def create_default_mapping(self) -> dict:
        """Crea el mapeo por defecto si no existe"""
        default = {
            "_metadata": {
                "name": "Mapeo por defecto",
                "description": "Mapeos genÃ©ricos",
                "version": "1.0"
            },
            "mappings": {
                "empresa": ["empresa.nombre"],
                "razon_social": ["empresa.nombre_completo"],
                "cif": ["empresa.cif"],
                "nif": ["empresa.cif"],
                "direccion": ["empresa.direccion"],
                "ciudad": ["empresa.ciudad"],
                "telefono": ["empresa.telefono"],
                "email": ["empresa.email"],
                "representante": ["representante.nombre_completo"],
                "cargo": ["representante.cargo"],
                "dni": ["representante.dni"],
                "fecha": ["_current_date"]
            }
        }
        
        filepath = os.path.join(MAPPINGS_DIR, 'default.json')
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(default, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"Error guardando mapeo default: {e}")
        
        return default
    
    def detect_mapping_for_template(self, template_name: str, doc_type: str = None) -> dict:
        """Detecta quÃ© mapeo usar segÃºn el nombre de la plantilla"""
        template_lower = template_name.lower()
        
        # PRIORIDAD 1: Usar la elecciÃ³n explÃ­cita del usuario
        if doc_type == 'detailed':
            print("âœ… Usando mapeo para documentos detallados (EIC) por elecciÃ³n del usuario.")
            return self.load_mapping_file('mapeo_eic_detallado.json')
        if doc_type == 'summary':
            print("âœ… Usando mapeo para resÃºmenes (PFAS) por elecciÃ³n del usuario.")
            return self.load_mapping_file('mapeo_resumen_corto.json')

        # Buscar en cache primero
        if template_name in self.mappings_cache:
            return self.mappings_cache[template_name]
        
        # Buscar archivo de mapeo especÃ­fico
        mapping_files = []
        if os.path.exists(MAPPINGS_DIR):
            mapping_files = [f for f in os.listdir(MAPPINGS_DIR) if f.endswith('.json')]
        
        # Intentar coincidencias
        for mapping_file in mapping_files:
            if mapping_file == 'default.json':
                continue
            
            mapping = self.load_mapping_file(mapping_file)
            if not mapping:
                continue
            
            # Verificar si el pattern coincide
            pattern = mapping.get('_metadata', {}).get('template_pattern', '')
            if pattern:
                if re.search(pattern, template_lower):
                    print(f"âœ… Usando mapeo: {mapping_file}")
                    self.mappings_cache[template_name] = mapping
                    return mapping
            
            # O si el nombre del mapping coincide con el nombre de la plantilla
            mapping_name = mapping_file.replace('.json', '')
            if mapping_name in template_lower or template_lower.replace('.docx', '').replace('.txt', '') in mapping_name:
                print(f"âœ… Usando mapeo: {mapping_file}")
                self.mappings_cache[template_name] = mapping
                return mapping
        
        # Si no encuentra, usar default
        print(f"âš ï¸ Usando mapeo por defecto")
        return self.default_mapping
    
    def list_mappings(self) -> str:
        """Lista los mapeos disponibles"""
        try:
            result = "ğŸ—ºï¸ **MAPEOS DISPONIBLES**\n\n"
            
            if not os.path.exists(MAPPINGS_DIR):
                return "âŒ No hay carpeta de mapeos"
            
            mapping_files = [f for f in os.listdir(MAPPINGS_DIR) if f.endswith('.json')]
            
            if not mapping_files:
                return "ğŸ“ No hay archivos de mapeo. Crea uno con: `crear mapeo: nombre`"
            
            for i, mapping_file in enumerate(mapping_files, 1):
                mapping = self.load_mapping_file(mapping_file)
                if mapping:
                    metadata = mapping.get('_metadata', {})
                    name = metadata.get('name', mapping_file)
                    desc = metadata.get('description', 'Sin descripciÃ³n')
                    num_fields = len(mapping.get('mappings', {}))
                    
                    result += f"{i}. **{mapping_file}**\n"
                    result += f"   ğŸ“ {name}\n"
                    result += f"   ğŸ’¬ {desc}\n"
                    result += f"   ğŸ”¢ {num_fields} campos mapeados\n\n"
            
            result += "\nğŸ’¡ **Crear nuevo:** `crear mapeo: mi_mapeo`"
            result += "\nğŸ’¡ **Ver mapeo:** `ver mapeo: default.json`"
            
            return result
            
        except Exception as e:
            return f"âŒ Error: {e}"
    
    def show_mapping(self, mapping_name: str) -> str:
        """Muestra el contenido de un mapeo"""
        try:
            if not mapping_name.endswith('.json'):
                mapping_name += '.json'
            
            mapping = self.load_mapping_file(mapping_name)
            
            if not mapping:
                return f"âŒ No se encontrÃ³ el mapeo: {mapping_name}"
            
            metadata = mapping.get('_metadata', {})
            mappings = mapping.get('mappings', {})
            
            result = f"ğŸ—ºï¸ **MAPEO: {mapping_name}**\n\n"
            result += f"**ğŸ“‹ InformaciÃ³n:**\n"
            result += f"   â€¢ Nombre: {metadata.get('name', 'N/A')}\n"
            result += f"   â€¢ DescripciÃ³n: {metadata.get('description', 'N/A')}\n"
            result += f"   â€¢ PatrÃ³n: {metadata.get('template_pattern', 'N/A')}\n"
            result += f"   â€¢ Total campos: {len(mappings)}\n\n"
            
            result += "**ğŸ”— Mapeos configurados:**\n"
            for i, (campo, rutas) in enumerate(list(mappings.items())[:15], 1):
                result += f"   {i}. {campo} â†’ {rutas[0]}\n"
            
            if len(mappings) > 15:
                result += f"\n   ... y {len(mappings) - 15} mÃ¡s\n"
            
            return result
            
        except Exception as e:
            return f"âŒ Error: {e}"
    
    def create_mapping_template(self, mapping_name: str, template_pattern: str = "") -> str:
        """Crea un nuevo archivo de mapeo"""
        try:
            if not mapping_name.endswith('.json'):
                mapping_name += '.json'
            
            filepath = os.path.join(MAPPINGS_DIR, mapping_name)
            
            if os.path.exists(filepath):
                return f"âŒ El mapeo {mapping_name} ya existe. Usa otro nombre."
            
            new_mapping = {
                "_metadata": {
                    "name": mapping_name.replace('.json', '').replace('_', ' ').title(),
                    "description": "Mapeo personalizado",
                    "template_pattern": template_pattern,
                    "version": "1.0",
                    "created": datetime.now().isoformat()
                },
                "mappings": {
                    "ejemplo_campo": ["empresa.nombre"],
                    "razon_social": ["empresa.nombre_completo"],
                    "fecha": ["_current_date"]
                }
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(new_mapping, f, indent=2, ensure_ascii=False)
            
            result = f"âœ… **MAPEO CREADO: {mapping_name}**\n\n"
            result += f"ğŸ“ UbicaciÃ³n: {filepath}\n\n"
            result += "**PrÃ³ximos pasos:**\n"
            result += "1. Edita el archivo JSON manualmente\n"
            result += "2. Agrega tus campos en la secciÃ³n 'mappings'\n"
            result += "3. Usa: `ver mapeo: {mapping_name}`\n"
            
            return result
            
        except Exception as e:
            return f"âŒ Error: {e}"

    # ============= GESTIÃ“N DE BASE DE DATOS MAESTRA =============
    
    def load_master_database(self) -> dict:
        """Carga la base de datos maestra con TODOS los datos del usuario"""
        if os.path.exists(self.user_database_file):
            try:
                with open(self.user_database_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return self.create_default_database()
        return self.create_default_database()
    
    def create_default_database(self) -> dict:
        """Crea base de datos por defecto"""
        default_data = {
            "_metadata": {
                "version": "1.0",
                "created": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "description": "Base de datos maestra del usuario/empresa"
            },
            
            # DATOS DE LA EMPRESA
            "empresa": {
                "nombre": "Mi Empresa S.L.",
                "nombre_completo": "Mi Empresa Sociedad Limitada",
                "nombre_comercial": "Mi Empresa",
                "cif": "B12345678",
                "direccion": "Calle Principal 123",
                "ciudad": "Madrid",
                "provincia": "Madrid",
                "codigo_postal": "28001",
                "pais": "EspaÃ±a",
                "telefono": "911234567",
                "email": "contacto@miempresa.com",
                "web": "www.miempresa.com",
                "sector": "TecnologÃ­a",
                "codigo_nace": "62.01",
                "aÃ±o_fundacion": "2020"
            },
            
            # REPRESENTANTE LEGAL
            "representante": {
                "nombre": "Juan",
                "apellidos": "PÃ©rez GarcÃ­a",
                "nombre_completo": "Juan PÃ©rez GarcÃ­a",
                "cargo": "Director General",
                "dni": "12345678X",
                "telefono": "611234567",
                "email": "jperez@miempresa.com"
            },
            
            # DATOS BANCARIOS
            "bancarios": {
                "banco": "Banco Ejemplo",
                "iban": "ES91 2100 0418 4502 0005 1332",
                "swift": "CAIXESBBXXX"
            },
            
            # PROYECTOS/SERVICIOS GENERALES
            "proyectos": {
                "principal": "Desarrollo de software innovador",
                "descripcion": "Soluciones tecnolÃ³gicas avanzadas para empresas",
                "objetivo": "Mejorar la eficiencia empresarial mediante tecnologÃ­a",
                "presupuesto": "75.000 â‚¬",
                "duracion": "12 meses"
            },
            
            # PROYECTO RED.ES IA
            "proyecto_redes": {
                "titulo_proyecto": "Plataforma de IA dual para optimizaciÃ³n industrial",
                "sector_productivo": "Industria 4.0 - Manufactura inteligente",
                "actividad_economica": "62.01 - ProgramaciÃ³n informÃ¡tica",
                "codigo_nace_proyecto": "25.50",
                
                "antecedentes": "Nuestra empresa cuenta con amplia experiencia en el desarrollo de soluciones de inteligencia artificial aplicadas al sector industrial. Durante los Ãºltimos aÃ±os, hemos identificado una creciente demanda de sistemas que integren capacidades de visiÃ³n por computador y procesamiento de lenguaje natural para optimizar procesos productivos.",
                
                "descripcion_general": "El proyecto propone desarrollar una plataforma integrada de IA dual que combine visiÃ³n artificial avanzada con procesamiento de lenguaje natural para automatizar la inspecciÃ³n de calidad y generaciÃ³n de informes en tiempo real en entornos industriales.",
                
                "difusion_resultados": "Los resultados del proyecto se difundirÃ¡n mediante: publicaciones en revistas tÃ©cnicas especializadas, participaciÃ³n en congresos nacionales e internacionales sobre IA industrial, organizaciÃ³n de workshops demostrativos con empresas del sector, y publicaciÃ³n de casos de uso en plataformas de cÃ³digo abierto.",
                
                "estrategia_mercado": "El mercado objetivo son empresas manufactureras medianas que requieren digitalizaciÃ³n de procesos de control de calidad. Se estima un mercado potencial en EspaÃ±a de 500Mâ‚¬. La estrategia incluye comercializaciÃ³n directa y alianzas con integradores industriales.",
                
                "grado_innovacion": "La soluciÃ³n aporta innovaciÃ³n tecnolÃ³gica al combinar tÃ©cnicas de deep learning con edge computing, permitiendo procesamiento en tiempo real con latencias inferiores a 100ms. A nivel de mercado, representa una novedad al integrar capacidades multimodales (visiÃ³n + lenguaje) en un Ãºnico sistema productivo.",
                
                "calidad_metodologia": "El proyecto seguirÃ¡ metodologÃ­a Ã¡gil con sprints de 3 semanas. Se aplicarÃ¡n estÃ¡ndares ISO 27001 para seguridad de datos, ISO 9001 para calidad del desarrollo, y se realizarÃ¡n revisiones tÃ©cnicas quincenales con validaciÃ³n de KPIs.",
                
                "planificacion": "Fase 1 (Meses 1-3): AnÃ¡lisis de requisitos y diseÃ±o arquitectÃ³nico. Fase 2 (Meses 4-9): Desarrollo iterativo de mÃ³dulos de IA. Fase 3 (Meses 10-11): IntegraciÃ³n, pruebas y validaciÃ³n. Fase 4 (Mes 12): Despliegue piloto y documentaciÃ³n.",
                
                "duracion": "12 meses (Inicio: 01/2025 - Fin: 12/2025)",
                
                "estructura_trabajo": "PT1: AnÃ¡lisis y arquitectura del sistema. PT2: Desarrollo mÃ³dulo de visiÃ³n artificial. PT3: Desarrollo mÃ³dulo NLP. PT4: IntegraciÃ³n de componentes. PT5: Testing, validaciÃ³n y documentaciÃ³n tÃ©cnica.",
                
                "fecha_inicio_estimada": "01/2025",
                "fecha_fin_estimada": "12/2025"
            },
            
            # DATOS PERSONALIZABLES
            "custom": {}
        }
        
        self.save_master_database(default_data)
        return default_data
    
    def save_master_database(self, data: dict) -> bool:
        """Guarda la base de datos maestra"""
        try:
            data["_metadata"]["last_updated"] = datetime.now().isoformat()
            
            with open(self.user_database_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            # Crear backup
            backup_file = self.user_database_file.replace('.json', '_backup.json')
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)

            return True
        except Exception as e:
            print(f"Error guardando base de datos: {e}")
            return False
    
    def update_master_database(self, updates: dict) -> str:
        """Actualiza campos especÃ­ficos de la base de datos"""
        try:
            def deep_update(base, update):
                for key, value in update.items():
                    if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                        deep_update(base[key], value)
                    else:
                        base[key] = value
            
            deep_update(self.user_database, updates)
            
            if self.save_master_database(self.user_database):
                return "âœ… Base de datos actualizada correctamente"
            return "âŒ Error guardando cambios"
            
        except Exception as e:
            return f"âŒ Error actualizando: {e}"
    
    def show_current_database(self) -> str:
        """Muestra los datos actuales de la base de datos"""
        try:
            result = "ğŸ—„ï¸ **BASE DE DATOS MAESTRA ACTUAL**\n\n"
            
            result += "**ğŸ¢ EMPRESA:**\n"
            for key, value in self.user_database.get('empresa', {}).items():
                if value:
                    result += f"   â€¢ {key}: {value}\n"
            
            result += "\n**ğŸ‘¤ REPRESENTANTE:**\n"
            for key, value in self.user_database.get('representante', {}).items():
                if value:
                    result += f"   â€¢ {key}: {value}\n"
            
            result += "\n**ğŸ¦ BANCARIOS:**\n"
            for key, value in self.user_database.get('bancarios', {}).items():
                if value:
                    result += f"   â€¢ {key}: {value}\n"
            
            result += "\n**ğŸ“Š PROYECTOS:**\n"
            for key, value in self.user_database.get('proyectos', {}).items():
                if value:
                    result += f"   â€¢ {key}: {value}\n"
            
            result += "\n**ğŸ¤– PROYECTO RED.ES IA:**\n"
            proyecto_redes = self.user_database.get('proyecto_redes', {})
            if proyecto_redes:
                campos_principales = ['titulo_proyecto', 'sector_productivo', 'duracion']
                for key in campos_principales:
                    if key in proyecto_redes and proyecto_redes[key]:
                        result += f"   â€¢ {key}: {proyecto_redes[key]}\n"
                result += f"   â€¢ (+ {len(proyecto_redes) - len(campos_principales)} campos mÃ¡s)\n"
            
            if self.user_database.get('custom'):
                result += "\n**ğŸ¨ CAMPOS PERSONALIZADOS:**\n"
                for key, value in self.user_database.get('custom', {}).items():
                    valor_corto = str(value)[:50] + '...' if len(str(value)) > 50 else str(value)
                    result += f"   â€¢ {key}: {valor_corto}\n"
            
            result += "\nğŸ’¡ **Para actualizar:** `actualizar datos: {json...}`"
            result += "\nğŸ’¡ **Ver proyecto Red.es:** `ver datos redes`"
            return result
            
        except Exception as e:
            return f"âŒ Error mostrando datos: {e}"
    
    def show_redes_project(self) -> str:
        """Muestra especÃ­ficamente los datos del proyecto Red.es"""
        try:
            result = "ğŸ¤– **PROYECTO RED.ES - CONVOCATORIA IA**\n\n"
            
            proyecto = self.user_database.get('proyecto_redes', {})
            
            if not proyecto:
                return "âŒ No hay datos del proyecto Red.es configurados"
            
            result += "**ğŸ“‹ DATOS GENERALES:**\n"
            result += f"   â€¢ TÃ­tulo: {proyecto.get('titulo_proyecto', 'No definido')}\n"
            result += f"   â€¢ Sector: {proyecto.get('sector_productivo', 'No definido')}\n"
            result += f"   â€¢ DuraciÃ³n: {proyecto.get('duracion', 'No definido')}\n"
            
            result += "\n**ğŸ“ SECCIONES DE LA MEMORIA:**\n"
            
            secciones = [
                ('antecedentes', 'Antecedentes'),
                ('descripcion_general', 'DescripciÃ³n General'),
                ('difusion_resultados', 'DifusiÃ³n de Resultados'),
                ('estrategia_mercado', 'Estrategia y Mercado'),
                ('grado_innovacion', 'Grado de InnovaciÃ³n'),
                ('calidad_metodologia', 'Calidad y MetodologÃ­a'),
                ('planificacion', 'PlanificaciÃ³n'),
                ('estructura_trabajo', 'Estructura de Trabajo')
            ]
            
            for key, nombre in secciones:
                valor = proyecto.get(key, '')
                if valor:
                    preview = valor[:80] + '...' if len(valor) > 80 else valor
                    result += f"\n   âœ… **{nombre}:**\n      {preview}\n"
                else:
                    result += f"\n   âŒ **{nombre}:** No definido\n"
            
            result += "\nğŸ’¡ **Para actualizar:** `actualizar datos: {\"proyecto_redes\": {...}}`"
            
            return result
            
        except Exception as e:
            return f"âŒ Error: {e}"

    # ============= MAPEO INTELIGENTE DE CAMPOS =============
    
    def _get_contextual_key(self, template_text: str, field_name: str) -> str:
        """
        Busca el texto de la secciÃ³n cercana al campo genÃ©rico (ej. 'texto_texto')
        para inferir la clave de la base de datos correcta.
        """
        if field_name not in ['texto_texto', 'mm_aaaa']:
            return field_name

        # Encontrar la posiciÃ³n del marcador en el texto
        pattern = re.escape(field_name)
        match = re.search(pattern, template_text)
        
        if not match:
            return field_name
        
        # Buscar la cabecera de la secciÃ³n mÃ¡s cercana antes del marcador
        # BÃºsqueda de texto anterior (ej. "1.1. Antecedentes y contexto del proyecto:")
        context_start = max(0, match.start() - 300) # Buscar hasta 300 caracteres antes
        preceding_text = template_text[context_start:match.start()].strip()
        
        # Intentar extraer el tÃ­tulo de la secciÃ³n (ej. con nÃºmeros y puntos)
        # PatrÃ³n mejorado para capturar la Ãºltima cabecera que termina en ':'
        last_header_match = re.findall(r'(\d+\.?\s*[^\n:]+):', preceding_text, re.IGNORECASE)
        
        if last_header_match:
            header = last_header_match[-1].strip()
            # Normalizar la cabecera para buscar la clave
            normalized_header = self.normalize_field_name(header)

            # Mapeo manual de la cabecera normalizada a la clave del proyecto
            if 'antecedentes' in normalized_header: return 'antecedentes'
            if 'descripcion_general' in normalized_header: return 'descripcion_general'
            if 'difusion_resultados' in normalized_header or 'difusion' in normalized_header: return 'difusion_resultados'
            if 'estrategia_mercado' in normalized_header: return 'estrategia_mercado'
            if 'grado_innovacion' in normalized_header: return 'grado_innovacion'
            if 'calidad_metodologia' in normalized_header or 'calidad' in normalized_header: return 'calidad_metodologia'
            if 'planificacion' in normalized_header: return 'planificacion'
            if 'fecha_inicio' in normalized_header: return 'fecha_inicio_proyecto' # Usa el alias general
            if 'fecha_finalizacion' in normalized_header: return 'fecha_fin_estimada_proyecto' # Usa el alias general
            
        return field_name # Devolver el nombre original si no se encuentra contexto
    
    # === Nuevo CÃ³digo para BÃºsqueda en Cascada ===
    def smart_field_mapping(self, field_name: str, template_name: str = None, template_text: str = None, doc_type: str = None) -> str:
        """Mapea un campo usando el mapeo apropiado, priorizando el mapeo especÃ­fico sobre el default."""
        
        # 1. Obtener configuraciones de mapeo
        # ğŸ‘‡ Â¡AQUÃ ESTÃ EL CAMBIO! Pasamos 'doc_type' a la siguiente funciÃ³n. ğŸ‘‡
        specific_mapping_config = self.detect_mapping_for_template(template_name, doc_type) if template_name else self.default_mapping
        default_mapping_config = self.default_mapping
        
        # Crear una lista de diccionarios de mapeo para buscar: [Mapeo EspecÃ­fico, Mapeo por Defecto]
        # Esto asegura que el mapeo mÃ¡s especÃ­fico (si no es el default) se compruebe primero.
        mappings_to_check = [specific_mapping_config.get('mappings', {})]
        if specific_mapping_config.get('_metadata', {}).get('name') != 'Mapeo por defecto':
            mappings_to_check.append(default_mapping_config.get('mappings', {}))
        
        # 2. ResoluciÃ³n Contextual para campos ambiguos (ej. [TEXTO])
        if template_text and field_name in ['texto_texto', 'mm_aaaa']:
            contextual_field_name = self._get_contextual_key(template_text, field_name)
            if contextual_field_name != field_name:
                field_name = contextual_field_name

        # 3. BÃºsqueda en Cascada (Priority Search)
        field_lower = field_name.lower().replace('_', ' ').replace('-', ' ')
        
        for field_mappings in mappings_to_check:
            # 3.1. BÃºsqueda por coincidencia exacta
            if field_name in field_mappings:
                paths = field_mappings[field_name]
                for path in paths:
                    value = self.get_nested_value(path, field_name)
                    if value: 
                        return value
            
            # 3.2. BÃºsqueda por similitud
            for key, paths in field_mappings.items():
                key_comparable = key.lower().replace('_', ' ').replace('-', ' ')
                if key_comparable == field_lower or key_comparable in field_lower or field_lower in key_comparable:
                    if field_name not in field_mappings: # Evitar doble chequeo de la clave exacta
                        for path in paths:
                            value = self.get_nested_value(path, field_name)
                            if value: 
                                return value

        # 4. Fallback: Buscar en 'custom'
        if field_name in self.user_database.get('custom', {}):
            return self.user_database['custom'][field_name]
        
        return None
        
    def format_list_field(self, field_name: str, separator: str = "\n") -> str:
        """Convierte listas de diccionarios o strings en texto plano para plantillas"""
        value = self.get_nested_value(field_name)
        if not value:
            return ""

        if isinstance(value, list):
            items = []
            for i, v in enumerate(value, 1):
                if isinstance(v, dict):
                    # Combina todos los valores del diccionario
                    item_text = ", ".join(f"{k}: {val}" for k, val in v.items())
                    items.append(f"{i}. {item_text}")
                else:
                    items.append(f"{i}. {v}")
            return separator.join(items)
        
        return str(value)

    
    def format_composite_field(self, template: str) -> str:
        """Formatea campos compuestos"""
        matches = re.findall(r'\{([^}]+)\}', template)
        result = template
        
        for match in matches:
            value = self.get_nested_value(match)
            if value:
                result = result.replace(f'{{{match}}}', str(value))
        
        return result
    
    def get_nested_value(self, path: str, field_name: str = None):
        """Obtiene valor anidado de la base de datos, aplicando formato si es necesario"""
        if path == '_current_date':
            return datetime.now().strftime("%d/%m/%Y")
        
        keys = path.split('.')
        value = self.user_database
        
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return None
        
        if value is None:
            return None
            
        # ğŸ†• Aplicar formato de fecha MM/AAAA si el campo final es mm_aaaa
        if field_name == 'mm_aaaa' or field_name == 'fecha_inicio_proyecto' or field_name == 'fecha_fin_estimada_proyecto':
            try:
                # Intentar parsear el valor a una fecha. Asumimos formatos comunes.
                if isinstance(value, str):
                    # Intentar YYYY-MM-DD
                    if re.match(r'\d{4}-\d{2}-\d{2}', value):
                        date_obj = datetime.strptime(value, "%Y-%m-%d")
                    # Intentar YYYY/MM/DD o DD/MM/YYYY si el formato es ambiguo
                    else:
                        date_obj = datetime.strptime(value, "%Y-%m-%d") # Esto puede fallar, pero es la mejor suposiciÃ³n
                elif isinstance(value, datetime):
                    date_obj = value
                
                # Devolver en formato MM/AAAA
                return date_obj.strftime("%m/%Y")
                
            except Exception as e:
                # Si el formato es un mes/aÃ±o ya listo (ej. 01/2025) o falla, lo devolvemos tal cual.
                return value
        
        return value if value else None

    # ============= RELLENADO AUTOMÃTICO PRINCIPAL =============
    
    def normalize_field_name(self, field_name: str) -> str:
        """
        Normaliza nombres de campos eliminando prefijos comunes, puntuaciÃ³n y acentos.
        Ej: '[Nombre/razÃ³n social]' -> 'razon_social'
        """
        field_normalized = field_name.strip()
        
        # 1. Eliminar corchetes, comillas y espacios iniciales/finales
        field_normalized = field_normalized.replace('[', '').replace(']', '').replace('"', '').strip()
        
        # 2. Eliminar prefijos comunes (mantenemos solo algunos para campos muy especÃ­ficos)
        prefixes_to_remove = [
            'Completar ', 'completar ', 'COMPLETAR ', 'Rellenar ', 'rellenar ',
        ]
        
        for prefix in prefixes_to_remove:
            if field_normalized.startswith(prefix):
                field_normalized = field_normalized[len(prefix):]
                break
        
        # 3. Eliminar acentos
        field_normalized = unidecode.unidecode(field_normalized)
        field_normalized = field_normalized.lower()
        
        # 4. Mapeos especÃ­ficos de alias
        if 'razon social' in field_normalized or 'nombre razon social' in field_normalized: return 'razon_social'
        if 'codigo nace' in field_normalized: return 'codigo_nace'
        if 'titulo de proyecto' in field_normalized or field_normalized == 'titulo': return 'titulo_proyecto'
        if 'sector productivo' in field_normalized: return 'sector_productivo'
        
        # 5. Limpiar el resto de caracteres especiales para estandarizar
        field_normalized = re.sub(r'[^\w]+', '_', field_normalized)
        field_normalized = re.sub(r'_{2,}', '_', field_normalized).strip('_')
        
        # 6. Mapeo final si el campo es genÃ©rico (ej. [TEXTO] -> texto_texto, [MM/AAAA] -> mm_aaaa)
        if field_normalized in ['texto']:
             return 'texto_texto' 
        if field_normalized in ['mm_aaaa']:
            return 'mm_aaaa'
        
        return field_normalized

    def auto_fill_with_database(self, filename: str, doc_type: str = None) -> str:
        """Rellena plantilla automÃ¡ticamente con base de datos maestra"""
        try:
            file_path = os.path.join(TEMPLATES_DIR, filename)
            if not os.path.exists(file_path):
                return f"âŒ No se encontrÃ³ la plantilla: {filename}"

            # 1. Cargar plantilla y extraer texto
            text_content = self.extract_text_from_file(file_path)
            
            # 2. Detectar campos
            campos_necesarios = set()
            campos_necesarios.update(re.findall(r'\{\{(\w+)\}\}', text_content))
            campos_necesarios.update(re.findall(r'\[([^\]]+)\]', text_content)) 
            campos_necesarios.update(re.findall(r'_(\w+)_', text_content))
            
            if not campos_necesarios:
                return "âŒ No se detectaron campos en la plantilla"
            
            # print(f"ğŸ“‹ Campos detectados: {campos_necesarios}")
            
            # 3. Normalizar y mapear campos a datos reales
            datos_mapeados = {}
            campos_sin_mapear = []
            
            for campo in campos_necesarios:
                campo_normalizado = self.normalize_field_name(campo)
                
                # ğŸ†• AquÃ­ se pasa el texto completo para el mapeo contextual
                valor = self.smart_field_mapping(campo_normalizado, filename, text_content, doc_type)
                
                if valor:
                    # Guardar con el nombre ORIGINAL del campo (para el reemplazo)
                    datos_mapeados[campo] = valor
                    # print(f"âœ… {campo} â†’ {valor[:50]}...")
                else:
                    campos_sin_mapear.append(campo_normalizado)
                    # print(f"âš ï¸ {campo} â†’ No encontrado en BD")
            
            # 4. Completar campos faltantes con IA
            # Esta secciÃ³n genera el contenido para los campos que no se encontraron,
            # lo que incluye las celdas de las tablas o campos que la lÃ³gica contextual fallÃ³ en resolver.
            if campos_sin_mapear:
                # Filtrar campos que ya fueron resueltos como 'texto_texto' pero que el mapeo simple no encontrÃ³
                # y los que realmente no tienen valor.
                campos_a_pedir_ia = [c for c in campos_sin_mapear if c != 'texto_texto'] 
                
                if campos_a_pedir_ia:
                    # print(f"ğŸ¤– Usando IA para {len(campos_a_pedir_ia)} campos...")
                    datos_ia = self._generate_realistic_data_with_ai(
                        text_content, 
                        campos_a_pedir_ia,
                        filename
                    )
                    # Mapear de vuelta a los nombres originales
                    for campo in campos_necesarios:
                        campo_norm = self.normalize_field_name(campo)
                        if campo_norm in datos_ia:
                            datos_mapeados[campo] = datos_ia[campo_norm]
            
            # 5. Agregar fecha
            datos_mapeados['fecha'] = datetime.now().strftime("%d/%m/%Y")
            datos_mapeados['Completar fecha'] = datetime.now().strftime("%d/%m/%Y")
            
            # 6. Rellenar documento
            output_name = f"{filename.split('.')[0]}_filled_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            extension = 'docx' if filename.endswith('.docx') else 'txt'
            output_filename = f"{output_name}.{extension}" 
            
            if filename.endswith('.docx'):
                result = self.fill_docx(file_path, datos_mapeados, output_name)
            elif filename.endswith('.txt'):
                result = self.fill_txt(file_path, datos_mapeados, output_name)
            else:
                return {
                    "success": False,
                    "error": "Formato no soportado",
                    "message": "âŒ Formato no soportado. Solo DOCX y TXT"
                }
            
            # 7. Generar estadÃ­sticas
            total_campos = len(campos_necesarios)
            desde_bd = total_campos - len(campos_sin_mapear)
            desde_ia = len(campos_sin_mapear)
            
            return {
                "success": True,
                "message": "âœ… Documento generado automÃ¡ticamente",
                "output_file": output_filename, 
                "template": filename,
                "total_campos": total_campos,
                "desde_bd": desde_bd,
                "desde_ia": desde_ia,
                "campos_bd": [campo for campo in datos_mapeados.keys() if self.normalize_field_name(campo) not in campos_sin_mapear][:10],
                "campos_ia": campos_sin_mapear[:5] if campos_sin_mapear else []
            }
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "message": f"âŒ Error en rellenado automÃ¡tico: {e}"
            }
              
    def _generate_realistic_data_with_ai(self, template_text: str, campos: list, filename: str) -> dict:
        """Usa Gemini para generar datos realistas para campos faltantes"""
        try:
            prompt = f"""
Genera datos realistas para estos campos de un documento de convocatoria de ayudas de I+D en IA, usando como contexto tu conocimiento sobre QUBIZ TEAM S.L. (InvestigaciÃ³n cuÃ¡ntica y detecciÃ³n de PFAS) y el documento.

CONTEXTO DEL DOCUMENTO (fragmento):
{template_text[:1500]}

CAMPOS A COMPLETAR (incluyendo las celdas de las tablas):
{', '.join(campos)}

Devuelve SOLO un JSON con formato:
{{
  "campo1": "valor realista y profesional",
  "campo2": "valor realista y profesional"
}}

Usa formato espaÃ±ol, lenguaje tÃ©cnico-profesional apropiado para proyectos de I+D en IA.
Para campos de texto largo, genera textos de al menos 150 palabras.
Para campos de tabla, genera valores coherentes (ej. ID, tipo, descripciÃ³n).
"""
            response = self.model.generate_content(prompt)
            response_text = response.text.strip()
            
            # Extraer JSON
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0]
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0]
            
            datos = json.loads(response_text)
            return datos
            
        except Exception as e:
            print(f"âš ï¸ Error con IA: {e}, usando valores genÃ©ricos")
            return {campo: f"[Completar {campo}]" for campo in campos}

    # ============= EXTRACCIÃ“N DE TEXTO =============
    
    def extract_text_from_file(self, file_path: str) -> str:
        """Extrae texto de diferentes formatos"""
        try:
            if file_path.endswith('.txt'):
                encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
                for encoding in encodings:
                    try:
                        with open(file_path, 'r', encoding=encoding) as f:
                            return f.read()
                    except UnicodeDecodeError:
                        continue
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    return f.read()

            elif file_path.endswith('.docx'):
                try:
                    doc = Document(file_path)
                    text = []
                    for paragraph in doc.paragraphs:
                        text.append(paragraph.text)
                    
                    # Extraer texto de tablas tambiÃ©n para el contexto
                    for table in doc.tables:
                        for row in table.rows:
                            for cell in row.cells:
                                for p in cell.paragraphs:
                                    text.append(p.text)
                    
                    return '\n'.join(text)
                except Exception as docx_error:
                    return f"Error procesando DOCX: {docx_error}"

            elif file_path.endswith('.pdf'):
                try:
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = []
                        for page in reader.pages:
                            text.append(page.extract_text())
                        return '\n'.join(text)
                except Exception as pdf_error:
                    return f"Error procesando PDF: {pdf_error}"

            return ""
        except Exception as e:
            return f"Error extrayendo texto: {e}"

    # ============= RELLENADO DE DOCUMENTOS =============
    
    def fill_txt(self, template_path: str, data: dict, output_name: str) -> str:
        """Rellena documento TXT"""
        try:
            content = ""
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
            
            for encoding in encodings:
                try:
                    with open(template_path, 'r', encoding=encoding) as f:
                        content = f.read()
                    break
                except UnicodeDecodeError:
                    continue
            
            if not content:
                with open(template_path, 'r', encoding='utf-8', errors='replace') as f:
                    content = f.read()

            if 'fecha' not in data:
                data['fecha'] = datetime.now().strftime("%d/%m/%Y")

            replacements = 0

            for key, value in data.items():
                if key.startswith('_'):
                    continue

                patterns = [f'{{{{{key}}}}}', f'[{key}]', f'_{key}_']
                for pattern in patterns:
                    if pattern in content:
                        content = content.replace(pattern, str(value))
                        replacements += 1

            output_path = os.path.join(OUTPUT_DIR, f"{output_name}.txt")
            with open(output_path, 'w', encoding='utf-8', newline='') as f:
                f.write(content)

            result = f"âœ… **DOCUMENTO RELLENADO**\n\n"
            result += f"ğŸ“„ Archivo: {output_name}.txt\n"
            result += f"ğŸ“ UbicaciÃ³n: {OUTPUT_DIR}/\n"
            result += f"ğŸ”„ Reemplazos: {replacements}\n"

            if replacements == 0:
                result += "\nâš ï¸ No se realizaron reemplazos. Verifica los marcadores."

            return result

        except Exception as e:
            return f"âŒ Error procesando TXT: {e}"
    
    def fill_docx(self, template_path: str, data: dict, output_name: str) -> str:
        """Rellena documento DOCX"""
        try:
            doc = Document(template_path)

            if 'fecha' not in data:
                data['fecha'] = datetime.now().strftime("%d/%m/%Y")

            replacements = 0

            # Rellenar pÃ¡rrafos
            for paragraph in doc.paragraphs:
                for key, value in data.items():
                    if key.startswith('_'):
                        continue

                    patterns = [f'{{{{{key}}}}}', f'[{key}]', f'_{key}_']
                    for pattern in patterns:
                        # Usar re.escape para manejar casos como [NIF] sin conflicto con regex
                        escaped_key = re.escape(key)
                        
                        # Buscar los patrones que envuelven la clave
                        regex_patterns = [
                            re.compile(r'\{\{' + escaped_key + r'\}\}', re.IGNORECASE),
                            re.compile(r'\[' + escaped_key + r'\]', re.IGNORECASE),
                            re.compile(r'_' + escaped_key + r'_', re.IGNORECASE)
                        ]
                        
                        for regex in regex_patterns:
                            if regex.search(paragraph.text):
                                paragraph.text = regex.sub(str(value), paragraph.text)
                                replacements += 1

            # Rellenar tablas
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        for key, value in data.items():
                            if key.startswith('_'):
                                continue

                            # Usar los patrones de regex como en pÃ¡rrafos
                            escaped_key = re.escape(key)
                            regex_patterns = [
                                re.compile(r'\{\{' + escaped_key + r'\}\}', re.IGNORECASE),
                                re.compile(r'\[' + escaped_key + r'\]', re.IGNORECASE),
                                re.compile(r'_' + escaped_key + r'_', re.IGNORECASE)
                            ]

                            # Iterar sobre los pÃ¡rrafos de la celda
                            for p in cell.paragraphs:
                                for regex in regex_patterns:
                                    if regex.search(p.text):
                                        p.text = regex.sub(str(value), p.text)
                                        replacements += 1


            output_path = os.path.join(OUTPUT_DIR, f"{output_name}.docx")
            doc.save(output_path)

            result = f"âœ… **DOCUMENTO RELLENADO**\n\n"
            result += f"ğŸ“„ Archivo: {output_name}.docx\n"
            result += f"ğŸ“ UbicaciÃ³n: {OUTPUT_DIR}/\n"
            result += f"ğŸ”„ Reemplazos: {replacements}\n"

            if replacements == 0:
                result += "\nâš ï¸ No se realizaron reemplazos. Verifica los marcadores."

            return result

        except Exception as e:
            return f"âŒ Error procesando DOCX: {e}"

    # ============= COMANDOS =============
    
    def run(self, prompt: str) -> str:
        """Procesa comandos para rellenar documentos"""
        prompt_original = prompt
        prompt = prompt.strip().lower()

        if "listar plantillas" in prompt:
            return self.list_templates()
        
        # ğŸ†• Comandos de mapeos
        elif "listar mapeos" in prompt:
            return self.list_mappings()
        
        elif prompt.startswith("ver mapeo:"):
            mapping_name = prompt[10:].strip()
            return self.show_mapping(mapping_name)
        
        elif prompt.startswith("crear mapeo:"):
            parts = prompt[12:].strip().split(" patron:")
            mapping_name = parts[0].strip()
            pattern = parts[1].strip() if len(parts) > 1 else ""
            return self.create_mapping_template(mapping_name, pattern)
        
        elif "ver datos redes" in prompt or "mostrar datos redes" in prompt:
            return self.show_redes_project()
        
        elif "ver datos" in prompt or "mostrar datos" in prompt:
            return self.show_current_database()
        
        elif "configurar datos" in prompt or "ayuda datos" in prompt:
            return self.show_database_config()
        
        elif prompt.startswith("actualizar datos:"):
            json_str = prompt_original[17:].strip()
            try:
                updates = json.loads(json_str)
                return self.update_master_database(updates)
            except json.JSONDecodeError as e:
                return f"âŒ JSON invÃ¡lido: {e}\n\nEjemplo correcto:\nactualizar datos: {{\"empresa\": {{\"nombre\": \"Nueva Empresa\"}}}}"
        
        #
        # ğŸ‘‡ ESTE ES EL BLOQUE MODIFICADO ğŸ‘‡
        #
        elif prompt.startswith("rellenar auto:"):
            command_part = prompt_original[14:].strip()
            doc_type = None

            # Busca el separador 'tipo:' sin importar mayÃºsculas/minÃºsculas
            split_keyword = " tipo:"
            split_index = command_part.lower().find(split_keyword)

            if split_index != -1:
                # Si lo encuentra, separa el nombre del archivo y el tipo
                filename = command_part[:split_index].strip()
                doc_type = command_part[split_index + len(split_keyword):].strip()
            else:
                # Si no, todo es el nombre del archivo
                filename = command_part

            return self.auto_fill_with_database(filename, doc_type)
        
        elif "listar datos" in prompt:
            return self.list_data_files()
        
        elif prompt.startswith("analizar:"):
            filename = prompt[9:].strip()
            return self.analyze_template(filename)
        
        elif prompt.startswith("crear ejemplo datos:"):
            filename = prompt[20:].strip()
            return self.create_example_data(filename)
        
        elif prompt.startswith("rellenar:"):
            command = prompt[9:].strip()
            return self.fill_document(command)
        
        elif prompt.startswith("usar plantilla:"):
            filename = prompt[15:].strip()
            copy_result = self.copy_default_template(filename)
            templates_result = self.list_templates()
            return f"{copy_result}\n\n{templates_result}"
        
        elif prompt.startswith("convertir a json:"):
            filename = prompt[len("convertir a json:"):].lstrip(": ").strip()
            return self.convert_to_json(filename)
        
        else:
            return self.show_help()
        
    def show_help(self) -> str:
        """Muestra ayuda del sistema"""
        return """
ğŸ“„ **SISTEMA DE RELLENADO DE DOCUMENTOS**

**âš¡ RELLENADO AUTOMÃTICO (Recomendado):**
   1. `ver datos` - Ver tu base de datos actual
   2. `rellenar auto: plantilla.docx` - Rellenar automÃ¡ticamente
   3. Â¡Listo! Descarga el documento generado

**ğŸ—ºï¸ GestiÃ³n de Mapeos:**
   â€¢ `listar mapeos` - Ver mapeos disponibles
   â€¢ `ver mapeo: default` - Ver contenido de un mapeo
   â€¢ `crear mapeo: mi_mapeo patron: .*solicitud.*` - Crear mapeo nuevo

**ğŸ¤– Proyectos Red.es IA:**
   â€¢ `ver datos redes` - Ver datos proyecto Red.es
   â€¢ `rellenar auto: plantilla_memoria_proyecto.docx` - Generar memoria

**ğŸ”§ ConfiguraciÃ³n de datos:**
   â€¢ `configurar datos` - Ver ayuda de configuraciÃ³n
   â€¢ `ver datos` - Mostrar datos actuales
   â€¢ `actualizar datos: {...}` - Actualizar tu informaciÃ³n

**ğŸ“‹ GestiÃ³n de plantillas:**
   â€¢ `listar plantillas` - Ver plantillas disponibles
   â€¢ `analizar: plantilla.txt` - Ver campos que necesita
   â€¢ `usar plantilla: nombre` - Copiar plantilla predeterminada

**ğŸ¯ Flujo recomendado:**
   1. Configura tus datos una vez (ver `configurar datos`)
   2. Sube tu plantilla .docx o .txt
   3. Usa `rellenar auto: tu_plantilla.docx`
   4. Â¡Descarga tu documento listo!

**ğŸ’¡ El sistema usa mapeos inteligentes y IA para completar campos**
        """
    
    def show_database_config(self) -> str:
        """Muestra ayuda para configurar la base de datos"""
        return """
ğŸ—„ï¸ **CONFIGURAR BASE DE DATOS MAESTRA**

**Tu base de datos se guarda en:** `data_docs/_master_user_data.json`

**Ejemplo - ConfiguraciÃ³n empresa:**

actualizar datos: {
  "empresa": {
    "nombre": "Tu Empresa Real S.L.",
    "cif": "B87654321",
    "direccion": "Avenida Principal 456",
    "ciudad": "Barcelona",
    "codigo_postal": "08001",
    "telefono": "932123456",
    "email": "info@tuempresa.es",
    "codigo_nace": "62.01"
  }
}

**Ejemplo - ConfiguraciÃ³n proyecto Red.es:**

actualizar datos: {
  "proyecto_redes": {
    "titulo_proyecto": "Tu tÃ­tulo de proyecto real",
    "sector_productivo": "Tu sector",
    "antecedentes": "Texto largo con antecedentes...",
    "descripcion_general": "DescripciÃ³n completa...",
    "estrategia_mercado": "Tu estrategia...",
    "grado_innovacion": "Aspectos innovadores..."
  }
}

**Ver configuraciÃ³n actual:**

ver datos
ver datos redes

**Una vez configurado:**
âœ… Todos los documentos se rellenarÃ¡n automÃ¡ticamente
âœ… Reutilizable para mÃºltiples convocatorias
        """

    # ============= FUNCIONES AUXILIARES =============
    
    def list_templates(self) -> str:
        """Lista las plantillas disponibles"""
        try:
            templates = []

            if os.path.exists(TEMPLATES_DIR):
                for file in os.listdir(TEMPLATES_DIR):
                    file_path = os.path.join(TEMPLATES_DIR, file)
                    if (os.path.isfile(file_path) and 
                        any(file.endswith(ext) for ext in self.supported_template_formats) and
                        file != "defaults"):
                        try:
                            size = os.path.getsize(file_path)
                            modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                            templates.append({
                                'name': file,
                                'size': f"{size/1024:.1f} KB",
                                'modified': modified.strftime("%Y-%m-%d %H:%M"),
                                'is_default': False
                            })
                        except Exception as e:
                            continue

            defaults_dir = os.path.join(TEMPLATES_DIR, "defaults")
            if os.path.exists(defaults_dir):
                for file in os.listdir(defaults_dir):
                    file_path = os.path.join(defaults_dir, file)
                    if (os.path.isfile(file_path) and 
                        any(file.endswith(ext) for ext in self.supported_template_formats)):
                        try:
                            size = os.path.getsize(file_path)
                            modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                            templates.append({
                                'name': file,
                                'size': f"{size/1024:.1f} KB",
                                'modified': modified.strftime("%Y-%m-%d %H:%M"),
                                'is_default': True
                            })
                        except Exception as e:
                            continue

            if not templates:
                return f"ğŸ“ **No hay plantillas**\n\nColoca archivos en: {TEMPLATES_DIR}/"

            result = "ğŸ“„ **PLANTILLAS DISPONIBLES:**\n\n"
            
            user_templates = [t for t in templates if not t['is_default']]
            default_templates = [t for t in templates if t['is_default']]
            
            if user_templates:
                result += "ğŸ‘¤ **Tus plantillas:**\n"
                for i, template in enumerate(user_templates, 1):
                    result += f"{i}. **{template['name']}**\n"
                    result += f"   ğŸ“Š {template['size']} | ğŸ“… {template['modified']}\n\n"
            
            if default_templates:
                result += "ğŸ­ **Plantillas predeterminadas:**\n"
                for i, template in enumerate(default_templates, 1):
                    result += f"{i}. **{template['name']}**\n"
                    result += f"   ğŸ“Š {template['size']}\n"
                    result += f"   ğŸ’¡ Usa: `usar plantilla: {template['name']}`\n\n"

            result += "\n**AcciÃ³n rÃ¡pida:** `rellenar auto: nombre_plantilla.docx`"
            return result

        except Exception as e:
            return f"âŒ Error listando: {e}"
    
    def list_data_files(self) -> str:
        """Lista archivos de datos"""
        try:
            data_files = []
            
            if not os.path.exists(DATA_DIR):
                os.makedirs(DATA_DIR, exist_ok=True)
                
            for file in os.listdir(DATA_DIR):
                if file.startswith('_'):
                    continue
                if any(file.endswith(ext) for ext in self.supported_data_formats):
                    file_path = os.path.join(DATA_DIR, file)
                    try:
                        size = os.path.getsize(file_path)
                        modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                        data_files.append({
                            'name': file,
                            'size': f"{size/1024:.1f} KB",
                            'modified': modified.strftime("%Y-%m-%d %H:%M"),
                            'type': file.split('.')[-1].upper()
                        })
                    except Exception as e:
                        continue

            if not data_files:
                return f"ğŸ“ **No hay archivos de datos**\n\nUsa tu base de datos con: `rellenar auto: plantilla.docx`"

            result = "ğŸ“Š **ARCHIVOS DE DATOS:**\n\n"
            for i, data_file in enumerate(data_files, 1):
                result += f"{i}. **{data_file['name']}** ({data_file['type']})\n"
                result += f"   ğŸ“Š {data_file['size']} | ğŸ“… {data_file['modified']}\n\n"

            return result

        except Exception as e:
            return f"âŒ Error: {e}"
    
    def analyze_template(self, filename: str) -> str:
        """Analiza campos de una plantilla"""
        try:
            file_path = os.path.join(TEMPLATES_DIR, filename)
            if not os.path.exists(file_path):
                return f"âŒ No se encontrÃ³: {filename}"

            text_content = self.extract_text_from_file(file_path)
            
            if not text_content or "Error" in text_content:
                return f"âŒ No se pudo leer: {filename}"

            marcadores = re.findall(r'\{\{(\w+)\}\}', text_content)
            marcadores.extend(re.findall(r'\[(\w+)\]', text_content))
            marcadores.extend(re.findall(r'_(\w+)_', text_content))

            result = f"ğŸ” **ANÃLISIS: {filename}**\n\n"

            if marcadores:
                result += "ğŸ“‹ **Campos detectados:**\n\n"
                for i, campo in enumerate(set(marcadores), 1):
                    # Usar el mapeo contextual para obtener el valor
                    valor = self.smart_field_mapping(self.normalize_field_name(campo), filename, text_content)
                    estado = "âœ… En BD" if valor else "âŒ Falta"
                    result += f"{i}. **{campo}** - {estado}\n"

                result += f"\nğŸ’¡ **AcciÃ³n:** `rellenar auto: {filename}`\n"
            else:
                result += "âš ï¸ No se identificaron campos\n"

            return result

        except Exception as e:
            return f"âŒ Error: {e}"
    
    def create_example_data(self, filename: str) -> str:
        """Crea datos de ejemplo para una plantilla"""
        try:
            file_path = os.path.join(TEMPLATES_DIR, filename)
            if not os.path.exists(file_path):
                return f"âŒ No se encontrÃ³: {filename}"

            text_content = self.extract_text_from_file(file_path)
            
            if not text_content or "Error" in text_content:
                return f"âŒ Error leyendo: {filename}"

            marcadores = set()
            marcadores.update(re.findall(r'\{\{(\w+)\}\}', text_content))
            marcadores.update(re.findall(r'\[(\w+)\]', text_content))
            marcadores.update(re.findall(r'_(\w+)_', text_content))

            ejemplo_datos = {}
            ejemplo_datos["_info"] = f"Datos ejemplo - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            ejemplo_datos["fecha"] = datetime.now().strftime("%d/%m/%Y")

            datos_tipicos = {
                "nombre": "Juan PÃ©rez GarcÃ­a",
                "empresa": "Innovaciones Tech SL",
                "mi_empresa": "Mi Empresa S.L.",
                "direccion_empresa": "Calle Mayor 123",
                "ciudad_codigo": "Madrid, 28001",
                "telefono": "911234567",
                "email": "info@empresa.com"
            }

            for marcador in marcadores:
                marcador_norm = self.normalize_field_name(marcador)
                if marcador_norm.lower() in datos_tipicos:
                    ejemplo_datos[marcador] = datos_tipicos[marcador_norm.lower()]
                else:
                    ejemplo_datos[marcador] = f"[COMPLETAR_{marcador_norm.upper()}]"

            if not marcadores:
                for key, value in datos_tipicos.items():
                    ejemplo_datos[key] = value

            json_filename = f"datos_ejemplo_{filename.split('.')[0]}.json"
            json_path = os.path.join(DATA_DIR, json_filename)

            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(ejemplo_datos, f, indent=2, ensure_ascii=False)

            result = f"âœ… **DATOS EJEMPLO CREADOS**\n\n"
            result += f"ğŸ“ {json_filename}\n\n"
            result += "ğŸ“‹ **Campos:**\n"

            for campo, valor in list(ejemplo_datos.items())[:8]:
                if campo != "_info":
                    result += f"â€¢ {campo}: {valor}\n"

            result += f"\nğŸ’¡ **Usa:** `rellenar: {filename} con {json_filename}`"

            return result

        except Exception as e:
            return f"âŒ Error: {e}"
    
    def fill_document(self, command: str) -> str:
        """Rellena documento con archivo de datos especÃ­fico"""
        try:
            if " con " not in command:
                return "âŒ Formato: `rellenar: plantilla.txt con datos.json`"

            parts = command.split(" con ")
            template_name = parts[0].strip()
            data_name = parts[1].strip()

            template_path = os.path.join(TEMPLATES_DIR, template_name)
            data_path = os.path.join(DATA_DIR, data_name)

            if not os.path.exists(template_path):
                return f"âŒ No se encontrÃ³ plantilla: {template_name}"

            if not os.path.exists(data_path):
                return f"âŒ No se encontrÃ³ datos: {data_name}"

            data = self.load_data(data_path)
            if not data:
                return f"âŒ No se pudieron cargar datos de: {data_name}"

            output_name = f"{template_name.split('.')[0]}_filled_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            if template_name.endswith('.docx'):
                return self.fill_docx(template_path, data, output_name)
            elif template_name.endswith('.txt'):
                return self.fill_txt(template_path, data, output_name)
            else:
                return f"âŒ Formato no soportado: {template_name}"

        except Exception as e:
            return f"âŒ Error: {e}"
    
    def load_data(self, data_path: str) -> dict:
        """Carga datos desde archivo"""
        try:
            if data_path.endswith('.json'):
                encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']
                for encoding in encodings:
                    try:
                        with open(data_path, 'r', encoding=encoding) as f:
                            return json.load(f)
                    except (UnicodeDecodeError, json.JSONDecodeError):
                        continue
                with open(data_path, 'r', encoding='utf-8', errors='replace') as f:
                    return json.load(f)

            elif data_path.endswith('.csv'):
                df = pd.read_csv(data_path, encoding='utf-8')
                if len(df) > 0:
                    return df.iloc[0].to_dict()
                return {}

            elif data_path.endswith('.xlsx'):
                df = pd.read_excel(data_path)
                if len(df) > 0:
                    return df.iloc[0].to_dict()
                return {}

            return {}
        except Exception as e:
            print(f"Error cargando datos: {e}")
            return {}
    
    def copy_default_template(self, filename: str) -> str:
        """Copia plantilla predeterminada"""
        defaults_dir = os.path.join(TEMPLATES_DIR, "defaults")
        src = os.path.join(defaults_dir, filename)
        dst = os.path.join(TEMPLATES_DIR, filename)
        
        if not os.path.exists(src):
            return f"âŒ Plantilla {filename} no existe en defaults"
        if os.path.exists(dst):
            return f"âš ï¸ {filename} ya existe"
        
        try:
            import shutil
            shutil.copy(src, dst)
            return f"âœ… Plantilla {filename} copiada"
        except Exception as e:
            return f"âŒ Error: {e}"
    
    def convert_to_json(self, filename: str) -> str:
        """Convierte archivos a JSON"""
        path = os.path.join(DATA_DIR, filename)
        if not os.path.exists(path):
            return f"âŒ No encontrado: {filename}"

        data = self.load_data(path)

        if not data:
            return "âŒ No se pudieron extraer datos"

        json_name = f"{filename.split('.')[0]}.json"
        json_path = os.path.join(DATA_DIR, json_name)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        preview = "\n".join([f"{k}: {v}" for i, (k, v) in enumerate(data.items()) if i < 10])
        if len(data) > 10:
            preview += "\nâ€¦"

        return f"âœ… Convertido a: {json_name}\n\nğŸ“‹ Preview:\n{preview}"


# Instancia global
document_filler = DocumentFiller()

def run(prompt: str) -> str:
    """FunciÃ³n principal"""
    return document_filler.run(prompt)